{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 类比推理\n",
    "\n",
    "本篇文档我们将使用已经训练好了的Glove向量来实现类比推理。因为词嵌入是需要很大的语料库很多的计算力很长的时间才能训练好的，所以通常我们都是使用前人已经训练好了的词嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from w2v_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的代码将加载词库中的单词到words里面，并返回一个word_to_vec_map字典，使用这个字典可以将单词转换成相应的Glove向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - 余弦相似Cosine similarity\n",
    "\n",
    "使用余弦cosine来判断两个词相似度的公式如下（u和v代表两个不同的词）： \n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u . v} {||u||_2 ||v||_2} = cos(\\theta) \\tag{1}$$\n",
    "\n",
    "$u.v$表示的是两个向量的点积（dot product）或内积（inner product）；$||u||_2$是向量u的范数(norm),$\\theta$是向量$u$ 和$v$之间的角度。如果向量u和v越相似余弦值就越接近1；如果它们越不相似，那么余弦值就会靠近-1。u的范数的定义是$ ||u||_2 = \\sqrt{\\sum_{i=1}^{n} u_i^2}$ \n",
    "\n",
    "<img src=\"images/cosine_sim.png\" style=\"width:800px;height:250px;\">\n",
    "<caption><center> **图 1**</center></caption>\n",
    "左图是法国france和意大利italy，它们都是国家名，所以很相似，所以角度很大，余弦值很大。中间的是两个不相干的词，角度成90度。右边的是两组词，一组是罗马rome意大利italy，另一组是法国france和巴黎paris，这两组词把国家和首都调换了位置，所以有了对立的关系，所以角度靠近180度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据上面的公式来实现使用余弦cosine判断两个词的相似度\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    \n",
    "    distance = 0.0\n",
    "    \n",
    "    dot = np.dot(u, v)\n",
    "    norm_u = np.sqrt(np.sum(u * u))\n",
    "    \n",
    "    norm_v = np.sqrt(np.sum(v * v))\n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.8909038442893615\n",
      "cosine_similarity(ball, crocodile) =  0.2743924626137942\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.6751479308174201\n"
     ]
    }
   ],
   "source": [
    "father = word_to_vec_map[\"father\"]\n",
    "mother = word_to_vec_map[\"mother\"]\n",
    "ball = word_to_vec_map[\"ball\"]\n",
    "crocodile = word_to_vec_map[\"crocodile\"]\n",
    "france = word_to_vec_map[\"france\"]\n",
    "italy = word_to_vec_map[\"italy\"]\n",
    "paris = word_to_vec_map[\"paris\"]\n",
    "rome = word_to_vec_map[\"rome\"]\n",
    "\n",
    "print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n",
    "print(\"cosine_similarity(ball, crocodile) = \",cosine_similarity(ball, crocodile))\n",
    "print(\"cosine_similarity(france - paris, rome - italy) = \",cosine_similarity(france - paris, rome - italy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你也可以修改上面单元测试里面的单词，来看看不同单词会有怎样的余弦值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 类比推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据word_a->word_b，推理出word_c->?\n",
    "\n",
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    \n",
    "    # 转换成小写\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    \n",
    "    #将单词转换成Glove向量\n",
    "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
    "    \n",
    "    words = word_to_vec_map.keys()\n",
    "    max_cosine_sim = -100             \n",
    "    best_word = None                 \n",
    "\n",
    "    # 遍历词表中的每个单词\n",
    "    for w in words:        \n",
    "        # 避免遇到已知的3个词word_a, word_b, word_c,如果遇到就跳到下一次循环，可以自行查阅continue的语法\n",
    "        if w in [word_a, word_b, word_c] :\n",
    "            continue\n",
    "        \n",
    "        ### 利用前面的函数进行相似性判断。\n",
    "        cosine_sim = cosine_similarity(e_b - e_a, word_to_vec_map[w] - e_c)\n",
    "        \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: spain -> spanish\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [('italy', 'italian', 'spain'), ('india', 'delhi', 'japan'), ('man', 'woman', 'boy'), ('small', 'smaller', 'large')]\n",
    "for triad in triads_to_try:\n",
    "    print ('{} -> {} :: {} -> {}'.format( *triad, complete_analogy(*triad, word_to_vec_map)))"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
