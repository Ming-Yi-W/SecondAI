{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ™ºèƒ½è¡¨æƒ…-å‡çº§ç‰ˆ \n",
    "\n",
    "ä¸Šä¸€ç¯‡æ–‡æ¡£æˆ‘ä»¬å®ç°äº†æ™ºèƒ½è¡¨æƒ…çš„æ¨¡å‹ï¼Œä½†æ˜¯æ¨¡å‹ä¼šå¿½ç•¥å¥å­ä¸­å•è¯çš„é¡ºåºã€‚æœ¬ç¯‡æ–‡æ¡£æˆ‘ä»¬ä¼šå®ç°ä¸€ä¸ªå‡çº§ç‰ˆçš„æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹ä¼šå‡†ç¡®åœ°åˆ†æå¥å­ä¸­å•è¯çš„é¡ºåºï¼Œæ›´åŠ åƒäººç±»ä¸€æ ·æ¥ç†è§£å¥å­çš„æ„æ€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from emo_utils import *\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - æ¨¡å‹æ¦‚å†µ\n",
    "\n",
    "æ¨¡å‹çš„æ¦‚å†µå›¾å¦‚ä¸‹:\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center>  </center></caption>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 é¢„å¤„ç†è¾“å…¥åºåˆ—\n",
    "\n",
    "å¤§å¤šæ•°æ·±åº¦å­¦ä¹ æ¡†æ¶éƒ½è¦æ±‚è¾“å…¥åºåˆ—çš„é•¿åº¦ä¸€è‡´ã€‚å› ä¸ºåªæœ‰é•¿åº¦ä¸€è‡´äº†æ¡†æ¶æ‰èƒ½åº”ç”¨å‘é‡åŒ–ç®—æ³•ï¼Œåœ¨ã€Š1.2.7 å‘é‡åŒ–ã€‹ä¸­æˆ‘ä»¬æåˆ°è¿‡å‘é‡åŒ–ç®—æ³•å¯ä»¥å¤§å¤§åœ°æå‡è®¡ç®—æ•ˆç‡ã€‚æœ¬ä¾‹ä¸­æˆ‘ä»¬å°†ä½¿ç”¨mini-batchæ¥è®­ç»ƒæ¨¡å‹ï¼Œå¦‚æœä¸€ä¸ªè¾“å…¥æ ·æœ¬å¥å­åºåˆ—é‡Œé¢æœ‰3ä¸ªå•è¯ï¼Œå¦ä¸€ä¸ªæœ‰4ä¸ªå•è¯ï¼Œé‚£ä¹ˆå‰ä¸€ä¸ªæ ·æœ¬éœ€è¦æ‰§è¡Œ3ä¸ªLSTMï¼Œåä¸€ä¸ªæ ·æœ¬éœ€è¦4ä¸ªLSTMï¼Œè¿™æ ·æ˜¯ä¸å¯èƒ½åº”ç”¨å‘é‡åŒ–ç®—æ³•çš„ã€‚\n",
    "\n",
    "ä¸ºäº†èƒ½ä½¿ç”¨å‘é‡åŒ–ç®—æ³•ï¼Œæˆ‘ä»¬éœ€è¦å¯¹è¾“å…¥åºåˆ—è¿›è¡Œpaddingæ“ä½œï¼Œä¹Ÿå°±æ˜¯å¯¹è¾“å…¥å¥å­è¿›è¡Œå¡«è¡¥æ“ä½œï¼Œå¯¹è¾“å…¥æ ·æœ¬è¿›è¡Œé¢„å¤„ç†ã€‚ä¾‹å¦‚æˆ‘ä»¬ä¼šè®¾å®šä¸€ä¸ªæœ€å¤§é•¿åº¦ï¼Œå‡è®¾æ˜¯20ï¼Œå¦‚æœå¥å­å•è¯æ•°ä¸æ»¡20ï¼Œé‚£ä¹ˆå°±ä¼šåé¢å¡«è¡¥0ï¼Œä¾‹å¦‚å¥å­\"i love you\"çš„ä¼šå˜æˆ$(e_{i}, e_{love}, e_{you}, \\vec{0}, \\vec{0}, \\ldots, \\vec{0})$ã€‚å¦‚æœå¥å­é•¿åº¦å¤§äº20ï¼Œé‚£ä¹ˆåé¢çš„å°±æˆªæ–­ä¸¢å¼ƒã€‚å½“ç„¶å¯ä»¥ç®€å•åœ°é€‰æ ·æœ¬ä¸­æœ€é•¿çš„å¥å­æœ€ä¸ºæœ€å¤§é•¿åº¦ï¼Œé‚£ä¹ˆå°±ä¸éœ€è¦æˆªæ–­æ“ä½œäº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Kerasè¯åµŒå…¥å±‚\n",
    "\n",
    "åœ¨Kerasæ¡†æ¶ä¸­ï¼Œè¯åµŒå…¥çŸ©é˜µæ˜¯ä»¥â€œlayerâ€ç½‘ç»œå±‚çš„å½¢å¼å­˜åœ¨çš„ã€‚è¿™ä¸ªè¯åµŒå…¥å±‚å¯ä»¥è‡ªå·±è®­ç»ƒï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯åµŒå…¥çŸ©é˜µæ¥åˆå§‹åŒ–å®ƒã€‚å› ä¸ºè®­ç»ƒè¯åµŒå…¥çŸ©é˜µéœ€è¦å¾ˆå¤šæ•°æ®å’Œæ—¶é—´ï¼Œæ‰€ä»¥æœ¬ä¾‹æˆ‘ä»¬ä¼šä¾ç„¶ä½¿ç”¨ä¹‹å‰è®­ç»ƒå¥½çš„è¯åµŒå…¥çŸ©é˜µæ¥åˆå§‹åŒ–Kerasçš„è¯åµŒå…¥å±‚ã€‚\n",
    "\n",
    "æœ‰äº†è¿™ä¸ªè¯åµŒå…¥å±‚â€œEmbeddingå±‚â€ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥å°†å•è¯çš„ç´¢å¼•è¾“å…¥ç»™å®ƒï¼Œå®ƒä¼šè¾“å‡ºå¯¹åº”çš„è¯åµŒå…¥ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º\n",
    "\n",
    "<img src=\"images/embedding1.png\" style=\"width:700px;height:250px;\">\n",
    "<caption><center> </center></caption>\n",
    "\n",
    "ä¸Šå›¾çš„æœ€å¤§é•¿åº¦æ˜¯5ï¼Œæ‰€ä»¥åœ¨ç¬¬ä¸€ä¸ªå¥å­åé¢æ·»åŠ äº†2ä¸ª0ï¼Œåœ¨ç¬¬äºŒä¸ªå¥å­åé¢æ·»åŠ äº†1ä¸ª0ã€‚Kerasçš„Embeddingå±‚è¾“å‡ºçš„ç»´åº¦å«ä¹‰åˆ†åˆ«æ˜¯ï¼ˆbatchå¤§å°ï¼Œæœ€å¤§é•¿åº¦ï¼ŒGloveå‘é‡çš„ç»´åº¦ï¼‰ã€‚\n",
    "\n",
    "é¦–å…ˆæˆ‘ä»¬å…ˆå°†å¥å­ä¸­å•è¯è½¬æ¢æˆç´¢å¼•ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†å•è¯è½¬æ¢ä¸ºç´¢å¼•ï¼Œå¹¶ä¸”å¡«å……0\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \n",
    "    m = X.shape[0]                                   # æ ·æœ¬æ•°\n",
    "    \n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):                               # éå†æ¯ä¸ªæ ·æœ¬\n",
    "        \n",
    "        # å°†å½“å‰å¥å­åˆ†å‰²æˆå•è¯ï¼Œå¹¶ä¸”å˜æˆå°å†™å­—æ¯\n",
    "        sentence_words = [w.lower() for w in X[i].split()]\n",
    "\n",
    "        j = 0\n",
    "        \n",
    "        # éå†æ¯ä¸ªå•è¯\n",
    "        for w in sentence_words:\n",
    "            # å°†å•è¯è½¬æ¢æˆç´¢å¼•\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            j += 1\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "\n",
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯åµŒå…¥çŸ©é˜µæ¥åˆå§‹åŒ–Kerasçš„Embeddingå±‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯åµŒå…¥çŸ©é˜µæ¥åˆå§‹åŒ–Kerasçš„Embeddingå±‚\n",
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1   # è·å–æ•´ä¸ªè¯è¡¨çš„å¤§å°ï¼ŒåŠ ä¸ª1æ˜¯å› ä¸ºKerasè¦æ±‚çš„\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # è·å–Gloveå‘é‡çš„ç»´åº¦ï¼Œè¿™ä¸ªæ˜¯50\n",
    "\n",
    "    # åˆå§‹åŒ–è¯åµŒå…¥çŸ©é˜µçš„ç»´åº¦ï¼ˆç´¢å¼•æ•°ï¼ŒGloveè®­ç»ƒç»´åº¦ï¼‰\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # ä¸ºæ¯ä¸ªç´¢å¼•è®¾ç½®å¯¹åº”çš„Gloveå‘é‡\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    # åˆ›å»ºEmbeddingå±‚ï¼Œ\n",
    "    # å‚æ•°trainableä¸€å®šè¦è®¾ç½®ä¸ºfalseï¼Œè¿™æ ·æ‰èƒ½ä¿è¯æ¨¡å‹è¿è¡Œæ—¶ä¸ä¼šéšç€è®­ç»ƒæ”¹å˜Embeddingé‡Œçš„è¯åµŒå…¥çŸ©é˜µçš„å€¼\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # å°†é¢„è®­ç»ƒå¥½çš„è¯åµŒå…¥çŸ©é˜µä½œä¸ºEmbeddingå±‚çš„æƒé‡æ¥åˆå§‹åŒ–è¯¥å±‚\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 æ„å»ºæ¨¡å‹\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center></center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºæ¨¡å‹\n",
    "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
    "    \n",
    "    # å°†sentence_indiceså®šä¹‰ä¸ºæ¨¡å‹çš„è¾“å…¥\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    # ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯åµŒå…¥çŸ©é˜µæ¥åˆ›å»ºä¸€ä¸ªembeddingå±‚\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # å°†è¾“å…¥ä¼ å…¥åˆ°embeddingå±‚ä¸­ï¼Œembeddingå±‚ä¼šè¾“å‡ºä¸è¾“å…¥ç´¢å¼•å¯¹åº”çš„è¯åµŒå…¥embeddings\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # å°†è¯åµŒå…¥embeddingsä¼ å…¥åˆ°ä¸€ä¸ªLSTMå±‚ä¸­ï¼Œreturn_sequencesä¸ºtrueå°±æ˜¯æ¯ä¸ªæ—¶é—´æ­¥éƒ½ä¼šæœ‰è¾“å‡º\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # åé¢åŠ ä¸€ä¸ªdropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # å°†è¯åµŒå…¥embeddingsä¼ å…¥åˆ°ä¸€ä¸ªLSTMå±‚ä¸­ï¼Œ\n",
    "    # return_sequencesä¸ºfalseå°±æ˜¯åªæœ‰æœ€åä¸€ä¸ªæ—¶é—´æ­¥æœ‰è¾“å‡ºï¼Œ\n",
    "    # å¤§å®¶å¯ä»¥çœ‹ä¸Šé¢çš„å›¾ï¼Œç¬¬ä¸€å±‚LSTMæ¯ä¸ªæ—¶é—´æ­¥éƒ½æœ‰è¾“å‡ºï¼Œç¬¬äºŒå±‚LSTMåªæœ‰æœ€åä¸€ä¸ªæ—¶é—´æ­¥æœ‰è¾“å‡º\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # åé¢åŠ ä¸€ä¸ªdropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    # ä¼ å…¥denseå±‚å¹¶è¿›è¡Œsoftmaxåˆ†ç±»ï¼Œç»™å‡º5ä¸ªæ¦‚ç‡\n",
    "    X = Dense(5)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # æ ¹æ®ä¸Šé¢çš„æ­¥éª¤åˆ›å»ºä¸€ä¸ªKerasæ¨¡å‹\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')\n",
    "maxLen = len(max(X_train, key=len).split())\n",
    "\n",
    "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ä¸ºè¯è¡¨ä¸­æœ‰400,001ä¸ªå•è¯ï¼Œæ‰€ä»¥æœ‰400,001\\*50 = 20,000,050ä¸ªå‚æ•°æ˜¯é¢„è®­ç»ƒå¥½äº†çš„ï¼Œæ‰€ä»¥æ˜¯non-trainableå‚æ•°ã€‚\n",
    "\n",
    "ä¸‹é¢å¯¹æ¨¡å‹è¿›è¡Œç¼–è¯‘ã€‚ç¼–è¯‘å‡½æ•°ä¸­è¦æŒ‡å®šä½¿ç”¨å“ªä¸ªæŸå¤±å‡½æ•°ä»¥åŠä¼˜åŒ–æ–¹æ³•ç­‰ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†æ•°æ®é›†è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œå¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - ETA: 0s - loss: 1.6064 - acc: 0.195 - 0s - loss: 1.6083 - acc: 0.1970     \n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s - loss: 1.5322 - acc: 0.2955     \n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s - loss: 1.5010 - acc: 0.3258     \n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s - loss: 1.4386 - acc: 0.3561     \n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s - loss: 1.3472 - acc: 0.4545     \n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s - loss: 1.2332 - acc: 0.5076     \n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s - loss: 1.1760 - acc: 0.4470     \n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s - loss: 1.0541 - acc: 0.5758     \n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s - loss: 0.8765 - acc: 0.7121     \n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s - loss: 0.8224 - acc: 0.6970     \n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s - loss: 0.7024 - acc: 0.7500     \n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s - loss: 0.6003 - acc: 0.8030     \n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s - loss: 0.4933 - acc: 0.8333     \n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s - loss: 0.5096 - acc: 0.8333     \n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s - loss: 0.4790 - acc: 0.8258     \n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s - loss: 0.3538 - acc: 0.8636     \n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s - loss: 0.3898 - acc: 0.8561     \n",
      "Epoch 18/50\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.6513 - acc: 0.812 - 0s - loss: 0.6520 - acc: 0.8106     \n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s - loss: 0.5176 - acc: 0.8182     \n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s - loss: 0.3966 - acc: 0.8409     \n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s - loss: 0.4691 - acc: 0.8182     \n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s - loss: 0.3874 - acc: 0.8636     \n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s - loss: 0.3763 - acc: 0.8561     \n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s - loss: 0.3048 - acc: 0.9091     \n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s - loss: 0.3444 - acc: 0.8864     \n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s - loss: 0.2429 - acc: 0.9394     \n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s - loss: 0.3152 - acc: 0.8788     \n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s - loss: 0.2413 - acc: 0.9318     \n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s - loss: 0.3910 - acc: 0.8712     \n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s - loss: 0.2647 - acc: 0.9091     \n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s - loss: 0.2950 - acc: 0.8864     \n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s - loss: 0.1999 - acc: 0.9394     \n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s - loss: 0.2101 - acc: 0.9470     \n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s - loss: 0.1590 - acc: 0.9621     \n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s - loss: 0.1645 - acc: 0.9621     - ETA: 0s - loss: 0.1171 - acc: 0.9\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s - loss: 0.1911 - acc: 0.9394     \n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s - loss: 0.1900 - acc: 0.9470     \n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s - loss: 0.2243 - acc: 0.9318     \n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s - loss: 0.1430 - acc: 0.9545     \n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s - loss: 0.1614 - acc: 0.9545     \n",
      "Epoch 41/50\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.0911 - acc: 0.984 - 0s - loss: 0.0886 - acc: 0.9848     \n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s - loss: 0.0843 - acc: 0.9773     \n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s - loss: 0.0829 - acc: 0.9848     \n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s - loss: 0.0512 - acc: 0.9924     \n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s - loss: 0.0771 - acc: 0.9848     \n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s - loss: 0.0939 - acc: 0.9773     \n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s - loss: 0.1372 - acc: 0.9470     \n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s - loss: 0.3138 - acc: 0.9242     \n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s - loss: 0.1051 - acc: 0.9848     \n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s - loss: 0.1479 - acc: 0.9545     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a83a3af60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)\n",
    "\n",
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”¨æµ‹è¯•é›†æ¥æµ‹è¯•æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/56 [================>.............] - ETA: 0s\n",
      "Test accuracy =  0.8214285629136222\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:ğŸ˜„ prediction: she got me a nice present\tâ¤ï¸\n",
      "Expected emoji:ğŸ˜ prediction: work is hard\tğŸ˜„\n",
      "Expected emoji:ğŸ˜ prediction: This girl is messing with me\tâ¤ï¸\n",
      "Expected emoji:ğŸ´ prediction: any suggestions for dinner\tğŸ˜„\n",
      "Expected emoji:â¤ï¸ prediction: I love taking breaks\tğŸ˜\n",
      "Expected emoji:ğŸ˜„ prediction: you brighten my day\tâ¤ï¸\n",
      "Expected emoji:ğŸ˜„ prediction: will you be my valentine\tâ¤ï¸\n",
      "Expected emoji:ğŸ´ prediction: See you at the restaurant\tâ¤ï¸\n",
      "Expected emoji:ğŸ˜ prediction: go away\tâš¾\n",
      "Expected emoji:ğŸ´ prediction: I did not have breakfast â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "# è¿™æ®µä»£ç åˆ—å‡ºäº†æ¨¡å‹å¯¹å“ªäº›æ ·æœ¬å¥å­é¢„æµ‹é”™äº†\n",
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šä¸€ç¯‡æ–‡æ¡£çš„æ¨¡å‹æ— æ³•å‡†ç¡®åœ°é¢„æµ‹â€œnot feeling happyâ€ï¼Œå› ä¸ºæ¨¡å‹å¿½ç•¥äº†å•è¯çš„é¡ºåºï¼Œåªæ˜¯ç®€å•åœ°æ±‚æ‰€æœ‰å•è¯çš„å¹³å‡å€¼ï¼Œè€Œåˆå› ä¸ºå¥å­ä¸­æœ‰happyè¿™ä¸ªå•è¯ï¼Œæ‰€ä»¥æ¨¡å‹ä¼šç»™å‡ºä¸€ä¸ªå¿«ä¹çš„è¡¨æƒ…ã€‚ä¸‹é¢æˆ‘ä»¬ä½¿ç”¨æœ¬æ–‡æ¡£çš„æ¨¡å‹å†æ¬¡æ¥é¢„æµ‹è¿™å¥è¯ï¼Œå¯ä»¥çœ‹åˆ°ç»“æœæ˜¯æ­£ç¡®çš„ï¼Œä¼šç»™å‡ºä¸€ä¸ªä¸å¼€å¿ƒçš„è¡¨æƒ…ã€‚\n",
    "\n",
    "å½“ç„¶ï¼ŒKeraså†…éƒ¨çš„å®ç°ä¼šæœ‰ä¸€å®šçš„éšæœºæ€§ï¼Œæ‰€ä»¥æœ‰æ—¶å€™å¯èƒ½ç»™å‡ºä¸ä¸€æ ·çš„ç»“æœã€‚è¿˜æœ‰å°±æ˜¯ï¼Œå› ä¸ºæˆ‘ä»¬çš„æ•°æ®é›†å¾ˆå°ï¼Œæ‰€ä»¥æ¨¡å‹å¯¹notå¥å‹è¿˜ä¸æ˜¯éå¸¸ç†Ÿæ‚‰ï¼Œæ‰€ä»¥æœ‰æ—¶å€™ä¹Ÿä¼šç»™å‡ºé”™è¯¯çš„é¢„æµ‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not feeling happy ğŸ˜\n"
     ]
    }
   ],
   "source": [
    "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  \n",
    "x_test = np.array(['not feeling happy'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
