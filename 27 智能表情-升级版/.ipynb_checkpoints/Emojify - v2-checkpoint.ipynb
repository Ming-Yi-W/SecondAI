{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ™ºèƒ½è¡¨æƒ… \n",
    "\n",
    "æˆ‘ä»¬åœ¨ç”¨å¾®ä¿¡QQèŠå¤©æ—¶ï¼Œç»å¸¸ä¼šåœ¨æ–‡å­—ä¸­åŠ å…¥ä¸€äº›è¡¨æƒ…ã€‚åŠ å…¥è¡¨æƒ…åèŠå¤©æ›´åŠ ç”ŸåŠ¨äº†ã€‚ä¸‹é¢ç»™å‡ºä¸€ä¸ªä¾‹å­ï¼š\n",
    "â€œæ­å–œä½ å‡èŒäº†! æˆ‘ä»¬å»å’–å•¡å…èŠèŠå§ã€‚çˆ±ä½ å“¦!â€\n",
    "â€œæ­å–œä½ å‡èŒäº†! ğŸ‘ æˆ‘ä»¬å»å’–å•¡å…èŠèŠå§ã€‚â˜•ï¸ çˆ±ä½ å“¦! â¤ï¸â€\n",
    " \"Congratulations on the promotion! ğŸ‘ Lets get coffee and talk. â˜•ï¸ Love you! â¤ï¸\"\n",
    "ç¬¬ä¸€å¥æ˜¯æ²¡æœ‰æ·»åŠ è¡¨æƒ…çš„ï¼Œç¬¬äºŒå¥æ˜¯æ·»åŠ äº†è¡¨æƒ…çš„ï¼Œç¬¬ä¸‰å¥æ˜¯å¯¹åº”çš„è‹±æ–‡ã€‚æ·»åŠ è¡¨æƒ…åçš„èŠå¤©æ›´åŠ ç”ŸåŠ¨äº†ã€‚\n",
    "\n",
    "æ™ºèƒ½è¡¨æƒ…æ˜¯æŒ‡AIæ ¹æ®èŠå¤©è¯­å¥è‡ªåŠ¨æ·»åŠ ç›¸åº”çš„è¡¨æƒ…ã€‚ä»¥å¾€æˆ‘ä»¬éƒ½æ˜¯æ‰‹åŠ¨æŸ¥æ‰¾è¾“å…¥è¡¨æƒ…çš„ï¼ŒAIè‡ªåŠ¨æ·»åŠ è¡¨æƒ…å¯ä»¥ä¸ºæˆ‘ä»¬èŠ‚çœæ—¶é—´ã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°†å®ç°ä¸€ä¸ªæ¨¡å‹ï¼Œå¾€é‡Œé¢è¾“å…¥ä¸€ä¸ªå¥å­åï¼Œæ¨¡å‹ä¼šç»™å‡ºåˆé€‚çš„è¡¨æƒ…ã€‚ä¾‹å¦‚è¾“å…¥â€œä»Šæ™šæˆ‘ä»¬å»çœ‹æ£’çƒæ¯”èµ›å§ï¼Let's go see the baseball game tonight!â€,æ¨¡å‹ä¼šè¾“å…¥æ£’çƒçš„è¡¨æƒ…âš¾ï¸ã€‚\n",
    "\n",
    "åœ¨å®ç°ä¸­æˆ‘ä»¬ä¼šç”¨åˆ°è¯åµŒå…¥å‘é‡ï¼Œè¿™æ ·å¯ä»¥å¤§å¤§æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚\n",
    "\n",
    "é¦–å…ˆæŒ‰ç…§ä¸‹é¢çš„æŒ‡ä»¤å®‰è£…ä¸¤ä¸ªæ–°çš„å·¥å…·åº“ã€‚\n",
    "\n",
    "1ï¼Œæ‰“å¼€Anaconda prompt\n",
    "\n",
    "2ï¼Œæ‰§è¡Œactivate tensorflowå‘½ä»¤\n",
    "\n",
    "3ï¼Œæ‰§è¡Œpip install emojiå‘½ä»¤\n",
    "\n",
    "4ï¼Œæ‰§è¡Œpip install sklearnå‘½ä»¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - æ•°æ®é›†\n",
    "\n",
    "æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†å¾ˆå°ï¼Œåªæœ‰127ä¸ªæ ·æœ¬:\n",
    "- X åŒ…å«äº†127ä¸ªè‹±æ–‡å¥å­\n",
    "- Y æ ‡ç­¾æ˜¯0åˆ°4çš„æ•°å­—ï¼Œæ¯ä¸ªæ•°å­—ä»£è¡¨äº†ä¸€ä¸ªè¡¨æƒ…ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬åªé¢„æµ‹5ä¸ªè¡¨æƒ…\n",
    "\n",
    "ä¸‹å›¾åˆ—ä¸¾äº†ä¸€äº›æ ·æœ¬\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **å›¾ 1**</center></caption>\n",
    "\n",
    "ä¸‹é¢çš„ä»£ç åŠ è½½äº†è®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ï¼Œè®­ç»ƒæ•°æ®é›†æœ‰127ä¸ªæ ·æœ¬ï¼Œæµ‹è¯•æ•°æ®é›†æœ‰56ä¸ªæ ·æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢çš„ä»£ç æ‰“å°å‡ºä¸€ä¸ªæ ·æœ¬çš„å¥å­Xï¼Œä»¥åŠè¿™ä¸ªå¥å­å¯¹åº”çš„Yæ ‡ç­¾ï¼Œå¹¶ä¸”å°†è¿™ä¸ªYæ ‡ç­¾è½¬åŒ–æˆè¡¨æƒ…å›¾æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am proud of your achievements ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - æ¨¡å‹ç®€è¿°\n",
    "\n",
    "ä¸‹é¢å°±æ˜¯æˆ‘ä»¬å°†è¦å®ç°çš„æ¨¡å‹çš„æ¦‚å›¾  \n",
    "\n",
    "<center>\n",
    "<img src=\"images/image_1.png\" style=\"width:900px;height:300px;\">\n",
    "<caption><center> **å›¾ 2**</center></caption>\n",
    "</center>\n",
    "\n",
    "å°†ä¸€ä¸ªæ ·æœ¬ä¸­Xï¼ˆä¹Ÿå°±æ˜¯ä¸€ä¸ªå¥å­ï¼‰ä¸­çš„æ‰€æœ‰å•è¯éƒ½è½¬æ¢æˆè¯åµŒå…¥å‘é‡ï¼Œç„¶åæ±‚è¿™äº›å‘é‡çš„å¹³å‡å€¼ï¼Œç„¶åå°†è¿™ä¸ªå¹³å‡å€¼å‘é‡è¾“å…¥åˆ°softmaxä¸­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†æ–¹ä¾¿è®¡ç®—ï¼Œæˆ‘ä»¬ä¸‹é¢å°†Yæ ‡ç­¾è½¬æ¢æˆone-hotå‘é‡çš„å½¢å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰“å°å‡ºä¸€ä¸ªYæ ‡ç­¾ï¼Œä»¥åŠå®ƒå¯¹åº”çš„one-hotå‘é‡å½¢å¼ã€‚å› ä¸ºä¸‹é¢è¿™ä¸ªYæ ‡ç­¾çš„å€¼æ˜¯0ï¼Œæ‰€ä»¥åœ¨one-hotå‘é‡ä¸­åªæœ‰ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯1ï¼Œå…¶å®ƒå…ƒç´ éƒ½æ˜¯0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is converted into one hot [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "index = 50\n",
    "print(Y_train[index], \"is converted into one hot\", Y_oh_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - å®ç°æ¨¡å‹\n",
    "\n",
    "é¦–å…ˆæˆ‘ä»¬éœ€è¦åŠ è½½å·²ç»è®­ç»ƒå¥½äº†çš„Gloveå‘é‡ç›¸å…³çš„å­—å…¸ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å°†å•è¯è½¬æ¢æˆGloveå‘é‡äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `word_to_index`: æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œåˆ©ç”¨è¿™ä¸ªå­—å…¸å¯ä»¥æ ¹æ®å•è¯å¾—åˆ°å…¶å¯¹åº”çš„ç´¢å¼•ï¼Œè¿™ä¸ªç´¢å¼•æ˜¯æŒ‡åœ¨è¯è¡¨ä¸­çš„ç´¢å¼•ã€‚è¯è¡¨ä¸­æœ‰400,001ä¸ªå•è¯ã€‚\n",
    "- `index_to_word`: åˆ©ç”¨è¿™ä¸ªå­—å…¸å¯ä»¥å°†ç´¢å¼•è½¬æ¢å•è¯ã€‚\n",
    "- `word_to_vec_map`: å•è¯è½¬Gloveå‘é‡çš„å­—å…¸\n",
    "\n",
    "ä¸‹é¢ä»£ç å±•ç¤ºäº†å•è¯å’Œç´¢å¼•ä¹‹é—´çš„è½¬æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 289846th word in the vocabulary is potatos\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 289846\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†å¥å­è½¬æ¢æˆGloveå‘é‡ï¼Œå¹¶ä¸”æ±‚å‡ºä¸€ä¸ªå¹³å‡å€¼å‘é‡\n",
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \n",
    "    # å–å‡ºå¥å­ä¸­çš„æ¯ä¸€ä¸ªå•è¯ï¼Œå¹¶ä¸”è½¬æ¢æˆå°å†™å½¢å¼\n",
    "    words = [i.lower() for i in sentence.split()]\n",
    "\n",
    "    avg = np.zeros((50,))\n",
    "    \n",
    "    # éå†æ¯ä¸€ä¸ªå•è¯ï¼Œå¹¶ä¸”è½¬æ¢æˆGloveå‘é‡ï¼Œç„¶åå°†æ¯ä¸ªå‘é‡ç´¯åŠ èµ·æ¥\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    # æ±‚å‡ºä¸€ä¸ªå¹³å‡å€¼å‘é‡\n",
    "    avg = avg / len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ä¸‹é¢æ˜¯è®¡ç®—zï¼Œaï¼Œä»¥åŠäº¤å‰ç†µcross-entropyæŸå¤±çš„å…¬å¼:\n",
    "$$ z^{(i)} = W . avg^{(i)} + b$$\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "\n",
    "    m = Y.shape[0]                          # è·å–æ ·æœ¬çš„ä¸ªæ•°\n",
    "    n_y = 5                                 # åˆ†ç±»ç§ç±»æ•°é‡\n",
    "    n_h = 50                                # Gloveå‘é‡çš„ç»´åº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯50ç»´çš„Gloveå‘é‡\n",
    "    \n",
    "    # åˆå§‹åŒ–å‚æ•°\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # å°†Yè½¬æ¢æˆone-hotå‘é‡çš„å½¢å¼\n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y) \n",
    "    \n",
    "    for t in range(num_iterations):                \n",
    "        for i in range(m): # éå†æ¯ä¸€ä¸ªæ ·æœ¬ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨çš„éšæœºæ¢¯åº¦ä¸‹é™,ä¹Ÿå°±æ˜¯ä¸€ä¸ªä¸€ä¸ªæ ·æœ¬çš„è¿›è¡Œè®­ç»ƒ\n",
    "            \n",
    "            # æ±‚å‡ºå½“å‰æ ·æœ¬å¥å­ä¸­å•è¯çš„å¹³å‡å€¼å‘é‡\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            z = np.dot(W, avg) + b\n",
    "            a = softmax(z)\n",
    "\n",
    "            # è®¡ç®—æŸå¤±\n",
    "            cost = -np.sum(np.multiply(Y_oh[i], np.log(a)))\n",
    "           \n",
    "            # åå‘ä¼ æ’­\n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            # æ›´æ–°å‚æ•°\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map)\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "Y = np.asarray([5,0,0,5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "\n",
    "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
    " 'Lets go party and drinks','Congrats on the new job','Congratulations',\n",
    " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
    " 'You totally deserve this prize', 'Let us go play football',\n",
    " 'Are you down for football this afternoon', 'Work hard play harder',\n",
    " 'It is suprising how people can be dumb sometimes',\n",
    " 'I am very disappointed','It is the best day in my life',\n",
    " 'I think I will end up alone','My life is so boring','Good job',\n",
    " 'Great so awesome'])\n",
    "\n",
    "print(X.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.952049881281007\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4 - æµ‹è¯•\n",
    "ä½¿ç”¨æµ‹è¯•é›†æ¥çœ‹çœ‹æ•ˆæœã€‚ä¸‹é¢çš„predictå‡½æ•°æ˜¯åœ¨è‡ªå®šä¹‰å·¥å…·åº“é‡Œé¢ä¸ºå¤§å®¶å®ç°äº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ä¸ºæ˜¯5é€‰1ï¼Œæ‰€ä»¥ççŒœçš„æ¦‚ç‡æ˜¯20%ï¼Œä¸Šé¢çš„æµ‹è¯•å‡†ç¡®ç‡è¾¾åˆ°äº†85%ï¼Œè¯´æ˜æ¨¡å‹æ•ˆæœè¿˜ä¸é”™ã€‚æˆ‘ä»¬çš„è®­ç»ƒé›†åªæœ‰127ä¸ªæ ·æœ¬å“¦ï¼è¿™ä¹ˆå°çš„è®­ç»ƒé›†å°±æœ‰è¿™ä¹ˆå¥½çš„æ•ˆæœï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº†é¢„è®­ç»ƒå¥½äº†çš„Gloveå‘é‡ã€‚\n",
    "\n",
    "è€Œä¸”Gloveå‘é‡è¿˜èµ‹äºˆäº†æ¨¡å‹å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œä¾‹å¦‚è®­ç»ƒé›†ä¸­çš„å¥å­\"*I love you*\"å¯¹åº”çš„è¡¨æƒ…æ˜¯â¤ï¸ï¼Œä¸‹é¢æˆ‘ä»¬å°†loveæ”¹æˆadoreï¼ˆçˆ±æ…•ï¼‰ï¼Œadoreæ˜¯ä¸åœ¨è®­ç»ƒé›†ä¸­çš„ï¼Œä½†æ˜¯æ¨¡å‹ä¾ç„¶èƒ½å‡†ç¡®çš„é¢„æµ‹å‡ºâ¤ï¸æ¥ã€‚å› ä¸ºè™½ç„¶æ¨¡å‹ä¹‹å‰æ²¡æœ‰æ¥è§¦è¿‡adoreè¿™ä¸ªå•è¯ï¼Œä½†æ˜¯adoreå’Œloveçš„Gloveå‘é‡çš„å€¼æ˜¯å¾ˆç›¸ä¼¼çš„ï¼Œä½¿ç”¨æ¨¡å‹ä¹Ÿèƒ½å‡†ç¡®çš„é¢„æµ‹å‡ºç»“æœã€‚å°±åƒç»™ä½ çœ‹äº†æ—¥æœ¬AVåï¼Œå½“æ—¶å½“ä½ çœ‹åˆ°æ¬§ç¾AVæ—¶ï¼Œä½ ä¹Ÿèƒ½ä¸€ä¸‹çŸ¥é“è¿™ä¸ªAVç‰‡ã€‚å› ä¸ºè™½ç„¶æ¬§ç¾äººä¸æ—¥æœ¬äººé•¿å¾—ä¸åŒï¼Œä½†æ˜¯AVæ˜¯æœ‰å¾ˆå¤šå…±åŒç‰¹æ€§çš„å‘€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you â¤ï¸\n",
      "i love you â¤ï¸\n",
      "funny lol ğŸ˜„\n",
      "lets play with a ball âš¾\n",
      "food is ready ğŸ´\n",
      "not feeling happy ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è™½ç„¶ä¸Šé¢çš„æ¨¡å‹è¡¨ç°å¾—ä¸é”™ï¼Œä½†æ˜¯å®ƒæœ‰ä¸€ä¸ªç¼ºç‚¹ï¼Œé‚£å°±æ˜¯å®ƒå¿½ç•¥äº†å•è¯çš„é¡ºåºï¼Œå› ä¸ºå®ƒåªæ˜¯å•çº¯åœ°æ±‚äº†æ¯ä¸ªå•è¯çš„å¹³å‡å€¼ã€‚æ‰€ä»¥å½“å®ƒé‡åˆ°\"æ„Ÿè§‰ä¸å¼€å¿ƒnot feeling happy\"æ—¶ï¼Œå®ƒä¹Ÿä¼šè®¤ä¸ºæ˜¯å¼€å¿ƒï¼Œå› ä¸ºé‡Œé¢æœ‰ä¸€ä¸ªhappyå•è¯ã€‚ä¸‹ä¸€ä¸ªå®æˆ˜ç¼–ç¨‹ä¸­ä¼šæ•™å¤§å®¶æ„å»ºä¸€ä¸ªä¸å¿½ç•¥å•è¯é¡ºåºçš„æ¨¡å‹ã€‚"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
